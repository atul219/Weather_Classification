# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cpBftlKRvxlWWfE3uWVWZVrK3M7IXy01
"""

import torch
from torch import nn, optim
from torchvision import datasets, transforms, models
from torch.utils.data.sampler import SubsetRandomSampler
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import argparse
import cv2
import os

# check if gpu is available or not

train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
	print("[INFO] Training on CPU.......")

else:
	print("[INFO] Training on GPU.......")

def display(train_data):

  images , labels = next(iter(train_loader))

  images.numpy()

  fig = plt.figure(figsize = (25,4))
  for idx in np.arange(20):
    ax = fig.add_subplot(2 , 10,  idx + 1, xticks = [], yticks = [])
    plt.imshow(np.transpose(images[idx], (1,2,0)))
    print(ax.set_title(classes[labels[idx]]))

data_dir = "drive/My Drive/dataset/train/"

# labels
classes = ["cloudy", "foggy", "rainy", "shine", "sunrise"]

# transforms 
train_transform = transforms.Compose([transforms.RandomResizedCrop(224),
                                      transforms.RandomHorizontalFlip(),
									                    transforms.ToTensor(),
                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])	




valid_size = 0.2




# laoding dataset from directory
train_data = datasets.ImageFolder(data_dir, transform = train_transform )



num_train = len(train_data)	
idx = list(range(num_train))	
np.random.shuffle(idx)

split = int(np.floor(valid_size * num_train))
train_idx , valid_idx = idx[split:] , idx[:split]

train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)




# train loader
train_loader = torch.utils.data.DataLoader(train_data , batch_size = 32 , sampler= train_sampler)

valid_loader = torch.utils.data.DataLoader(train_data , batch_size = 32 ,  sampler = valid_sampler)

train_data

t_img , t_label = next(iter(train_loader))
v_img , v_label = next(iter(valid_loader))

print("[INFO] Training data length.......: {}".format(len(train_data)))
t_label

# load the pretrained model

vgg = models.vgg16(pretrained = True)

vgg

# if train_on_gpu:
#   print("CUDA")
#   vgg.cuda()

# freeze all parameters of network except classifier
for param in vgg.features.parameters():
	param.requires_grad = False

in_features = 25088

classifier = nn.Sequential(nn.Linear(in_features , 512),
							nn.ReLU(),
							nn.Linear(512 , 5))

vgg.classifier = classifier

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(vgg.classifier.parameters() , lr = 0.01)

n_epochs = 4
total_train_loss, total_valid_loss = [], []
step = 0
accuracy = []
valid_loss_min = np.Inf

for e in range(n_epochs + 1):

  train_loss = 0
  valid_loss = 0

  vgg.train()
  for images, labels in train_loader:


    # if train_on_gpu:
    #   images , labels = images.cuda(), labels.cuda()

    optimizer.zero_grad()

    output = vgg(images)

    loss = criterion(output , labels)

    loss.backward()

    optimizer.step()

    train_loss += loss.item()*images.size(0)

    if step % 5 == 0:
      print("Step {}  \tTraining Loss: {:.4f}".format(step , train_loss))

    

    step += 1


  vgg.eval()
  for images, labels in valid_loader:

    optimizer.zero_grad()

    output = vgg(images)

    loss = criterion(output , labels)


    valid_loss += loss.item()*images.size(0)

   
  train_loss = train_loss / len(train_loader.sampler)
  valid_loss = valid_loss / len(valid_loader.sampler)


  total_train_loss.append(train_loss / len(train_loader.sampler))
  total_valid_loss.append(valid_loss / len(valid_loader.sampler))

  print("Epoch: {}, \tTraining Loss: {:.4f},    \tValidation Loss: {:.4f}".format(e + 1 , train_loss, valid_loss))


  # saving model
  if valid_loss <= valid_loss_min:
    print("Validation Loss Decreased ({:.6f} ----> {:.6f}). Saving Model........ ".format(valid_loss_min , valid_loss))

    torch.save(vgg.state_dict(), "drive/My Drive/dataset/weather_model.pt")
    valid_loss_min = valid_loss

# Load Modlel
vgg.load_state_dict(torch.load("drive/My Drive/dataset/weather_model.pt"))

test_transform = transforms.Compose([transforms.RandomResizedCrop(224),
                                      transforms.RandomHorizontalFlip(),
									                    transforms.ToTensor(),
                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])



test_data = datasets.ImageFolder("drive/My Drive/dataset/test" , transform= test_transform)

test_loader = torch.utils.data.DataLoader(test_data, batch_size= 32)

import pandas as pd

dl = pd.read_csv("drive/My Drive/dataset/test.csv")

test_label = dl["labels"]

test_label = torch.tensor(test_label)
type(test_label)

test_loss = 0.0
cls_correct = 0


vgg.eval()

for data in test_loader:

  img, _ = data

  output = vgg(img)

  loss = criterion(output, test_label)

  test_loss += loss.item()*img.size(0)

  _, pred = torch.max(output, 1)

  pred = pred.numpy()

  for i in range(len(pred)):
    if test_label[i] == pred[i]:
      cls_correct += 1

test_loss = test_loss / len(test_loader)

acc = 100 * (cls_correct / len(test_label))

print("Accuracy: {}".format(acc))

img, _ = data

cr = 0
for i in range(len(label)):
  if label[i] == prediction[i]:
    cr += 1

